{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 4-1 homework: Simple supervised learning\n",
    "\n",
    "For this assignment you will use a decision tree to figure out which type of grape was used to make each wine, starting from an analysis of 13 different aspects of chemical composition. \n",
    "\n",
    "This is a classic machine learning test data set, originally from [here](https://archive.ics.uci.edu/ml/datasets/wine). I've edited it to remove a space in front of each column name, though!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Using a decision tree to figure out which wine is which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in wine.csv and take a look at it. We will predict the variable \"wine_cultivar\" \n",
    "# This variable represents the type of grape: Shiraz, merlot, pinot, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's get an idea of the structure of this data.\n",
    "# Use scatter_matrix to create a plot of the first few variables, using wine_cultivar as the color.\n",
    "scatter_matrix(df[['Alcohol','Malic_acid','Ash']],c=df.wine_cultivar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split off a random fifth of this data to use for testing. How many rows examples are in each set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of the column names of the features. This is every column except the answer we are predicting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a decision tree to the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you got graphviz to install correctly, draw a picture of the tree here\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well does this tree do on the training data? \n",
    "# Compute the predicted wine_cultivar, and use this to print out the accuracy and confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict wine_cultivar on the test data. What is the accuracy and confusion matrix on the test data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Binary classification metrics\n",
    "In this section we'll train a basic classifier on our favorite Titantic data, and then calculate some accuracy metrics for a binary predictor that we will be using over and over again in our upcoming discussion of algorithmic accountability.\n",
    "\n",
    "Most of the code for this section is copied from the solution to Homework 3.2. This assignment is just to make sure you understand how to calculate the various accuracy metrics at the end.\n",
    "\n",
    "For your reference, Wikipedia has an [amazing chart](https://en.wikipedia.org/wiki/Confusion_matrix) of the various things you can calculate from a binary confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load titanic.csv once more\n",
    "ti = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recode the pclass and gender variables so they are numeric\n",
    "ti.pclass = ti.pclass.replace({'1st':1, '2nd':2, '3rd':3})\n",
    "ti['female'] = ti.gender.replace({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set aside a third of the data for testing.\n",
    "# (Set random_state to some number to ensure we get the same split each time, \n",
    "# so everyone's answers will be the same and we can mark this easily.)\n",
    "ti_train, ti_test = train_test_split(ti, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up x and y variables and train a decision tree on the pclass and sex features, to predict survived\n",
    "feature_columns = ['pclass','female']\n",
    "ti_x = ti_train[feature_columns].values\n",
    "ti_y = ti_train[['survived']].values\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(ti_x,ti_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create ti_test and ti_test values, and use the classifier to predict yti_test_pred\n",
    "ti_x_test = ti_test[feature_columns].values\n",
    "ti_y_test = ti_test[['survived']].values\n",
    "ti_y_test_pred = dt.predict(ti_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the confusion matrix for the classifier. Use the DataFrame trick we saw in class to label the axes.\n",
    "pd.DataFrame(metrics.confusion_matrix(ti_y_test, ti_y_test_pred), \n",
    "             columns=['Predicted 0','Predicted 1'],\n",
    "             index=['True 0', 'True 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ok! What are the number of true positives, true negatives, false positives, and false negatives?\n",
    "TP = \n",
    "TN = \n",
    "FP = \n",
    "FN = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the varaibles TP,TN,FP,FN, calculate and print the overall accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that you have your calculation right by comparing to metrics.accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the varaibles TP,TN,FP,FN, calculate and print the false positive rate and the false negative rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute and print the precision aka positive predictive value, again from these four variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what precision means, in words that an average reader could understand. Also explain what this particular precision value means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Logistic regression classifier on the wine data\n",
    "Fit a logistic regression to the same wine data. How well does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a LogisticRegression model to the wine data (x_train, y_trin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well does logistic regression do on the training data? Print the accuracy and confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well does logistic regression do on the test data (x_test, y_test)? Print the accuracy and confusion matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
