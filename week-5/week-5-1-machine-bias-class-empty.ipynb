{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5-1: Breaking down Machine Bias\n",
    "\n",
    "This notebook explores the classic ProPublica story [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing). It uses the original data that the reporters collected for the story, through FOIA requests to Broward County, Florida.\n",
    "\n",
    "The COMPAS score uses answers to [137 questions](https://www.documentcloud.org/documents/2702103-Sample-Risk-Assessment-COMPAS-CORE.html) to assign a risk score to defendents -- essentially a probability of re-arrest. The actual output is two-fold: a risk rating of 1-10 and a \"low\", \"medium\", or \"high\" risk label\n",
    "\n",
    "This analysis is based on ProPublica's [original notebook](https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb)\n",
    "\n",
    "There has been a lot of discussion about this story and its particular definition of fairness. The best overall reference is the [Fairness in Machine Learning\n",
    "NIPS 2017 Tutorial](http://fairml.how) by Solon Barocas and Moritz Hardt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to let you select between data on arrests for non-violent or violent crimes. This allows quick comparisons of the difference between these two data sets.\n",
    "\n",
    "\n",
    "There is some reason to suspect that arrest data for violent crime is both more accurate and less biased than non-violent crime data. See e.g. [Skeem and Lowenkamp](https://www.law.berkeley.edu/wp-content/uploads/2015/04/SSRN-id2687339.pdf). Also, we do get more accurate predictors wih the violent data (including COMPAS).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "violent = False\n",
    "\n",
    "if violent:\n",
    "    fname ='compas-scores-two-years-violent.csv'\n",
    "    decile_col = 'v_decile_score'\n",
    "    score_col = 'v_score_text'\n",
    "else:\n",
    "    fname ='compas-scores-two-years.csv'\n",
    "    decile_col = 'decile_score'\n",
    "    score_col = 'score_text'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pd.read_csv(fname)\n",
    "cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following ProPublica, we filter out certain rows which are missing data. As they put it:\n",
    "\n",
    "- If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
    "- We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "- In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed\n",
    "- We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cv[\n",
    "    (cv.days_b_screening_arrest <= 30) &  \n",
    "    (cv.days_b_screening_arrest >= -30) &  \n",
    "    (cv.is_recid != -1) &\n",
    "    (cv.c_charge_degree != 'O') &\n",
    "    (cv[score_col] != 'N/A')\n",
    "]\n",
    "\n",
    "cv.reset_index(inplace=True, drop=True) # renumber the rows from 0 again\n",
    "cv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A first look at the data \n",
    "\n",
    "Let's do some basic analysis on the demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age value coutns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race value counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The COMPAS model predictions are in `v_decile_score` from 1 to 10, and low/med/high in `v_score_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPAS decile score value counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPAS text score value counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the decile scores white and black to get our first look at how the COMPAS algorithm handles different races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of decile scores for White\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram of decile scores for Black\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile the `two_year_recid` field records whether or not each person was re-arrested for a violent offense within two years, which is what COMPAS is trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recidivism value counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start looking at the relationships between these variables. First, recidivism by race.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# recidivism rates by race\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recidivism rates by sex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are significant differences in recidivisim in this population by race and gender. These are the \"base rates\" we will talk about more. However, there may also be significant differences in the composition of these populations -- they may have different age, criminal histories, etc.\n",
    "\n",
    "Let's see how the COMPAS risk scores break down by race and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high risk rates by race\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high risk rates by sex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the fraction of people assigned a `high` risk is greater where the recidivism rates are also higher. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive calibration and accuracy\n",
    "Being \"accurate\" in a predictive sense is only one type of \"fairness,\" as we shall see, but it's still a desirable characteristic.\n",
    "\n",
    "Let's start by looking at the proportion of people who are re-arrested in each decile score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of recidivism by decile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# probability of recidivism by decile and race\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome variable `two_year_recid` is the actually observed results in the world, and it is binary -- was this person re-arrested within two years of their initial arrest and risk score assignment? To work with this data further we're going to simplify the COMPAS classifier scores  it by thresholding them into a binary variable as well. ProPublica splits \"low\" from \"medium or high\" risk, according to their [methodology](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm). \n",
    "\n",
    "Using this binary prediction variable lets us compute a confusion matrix for the COMPAS algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPAS recidivism confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the information about binary classifier performance and error (for a particular group) is in a 2x2 confusion matrix (also called a contingency table.) But we're usually interested in rates as opposed to raw numbers, so we're going to convert this table into the following values:\n",
    "\n",
    "- Accuracy: the fraction of guesses that were correct\n",
    "- Precision or Positive Predictive Value: of the people we guessed would recidivate, what fraction did?\n",
    "- False Positive Rate: of the people who didn't recidivate, how many did we guess would?\n",
    "- False Negative Rate: of the people who did recidivate, how many did we guess would not?\n",
    "\n",
    "There's a wonderful little [diagram on the qauntitative definitions of fairness](https://speak-statistics-to-power.github.io/fairness/#definitions-metric-parities) page that shows how all of these relate, and Wikipedia is also a [good reference](https://en.wikipedia.org/wiki/Confusion_matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The usual definitions. First index is predicted, second is actual\n",
    "TN = cm[False][False]\n",
    "TP = cm[True][True]\n",
    "FN = cm[False][True]\n",
    "FP = cm[True][False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 63% of those scored as medium or high risk end up getting arrested again within two years. This is the **Positive Predictive Value (PPV)** or **Precision**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of those who did not go on to be re-arrested, about 30% were classified as medium or high risk. This is the **False Positive Rate (FPR)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may help to understand many of these formulas if we define variables for the total number of true positive and negative cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = TP + FN\n",
    "N = TN + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent definition of FPR that might be easier to understand, N in denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the **False Negative Rate (FNR)** which counts those who were  classified as low risk, as a fraction of those who were re-arrested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate form with P in denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study the difference betwen races, let's define a few helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cm is a confusion matrix. The rows are guessed, the columns are actual \n",
    "def print_ppv_fpv(cm):\n",
    "    # the indices here are [col][row] or [actual][guessed]\n",
    "    TN = cm[False][False]   \n",
    "    TP = cm[True][True]\n",
    "    FN = cm[True][False]\n",
    "    FP = cm[False][True]\n",
    "    print('Accuracy: ', (TN+TP)/(TN+TP+FN+FP))\n",
    "    print('PPV: ', TP / (TP + FP))\n",
    "    print('FPR: ', FP / (FP + TN))\n",
    "    print('FNR: ', FN / (FN + TP))\n",
    "    print()\n",
    "\n",
    "def print_metrics(guessed, actual):\n",
    "    cm = pd.crosstab(guessed, actual, rownames=['guessed'], colnames=['actual'])\n",
    "    print(cm)\n",
    "    print()\n",
    "    print_ppv_fpv(cm)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_metrics for white and black defendants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the statistical core of ProPublica's story: the False Positive Rate is substantially higher for black defendants. \n",
    "\n",
    "However, also note that the PPV is similar between black and white. In fact the lower PPV for white means the score is has greater predictive accuracy for black defendants. Here \"accurate\" measures the proportion of people that actually were re-arrested, as a proportion of the people that COMPAS guessed would be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic regression to build our own predictor\n",
    "\n",
    "We are going to use logistic regression to try to build our own predictor, just from the information we we have. This is actually quite a lot:\n",
    "- Age\n",
    "- Sex\n",
    "- Felony or Misdemeanor charge (`c_charge_degree`)\n",
    "- Number of prior arrests (`c_priors_count`)\n",
    "\n",
    "And we'll try this both with and without race as a predictive factor, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build up dummy variables for age, race, gender\n",
    "features = pd.concat(\n",
    "    [pd.get_dummies(cv.age_cat, prefix='age'),\n",
    "     pd.get_dummies(cv.sex, prefix='sex'),\n",
    "     pd.get_dummies(cv.c_charge_degree, prefix='degree'), # felony or misdemeanor charge ('f' or 'm')\n",
    "     cv.priors_count],\n",
    "    axis=1)\n",
    "\n",
    "# We should have one less dummy variable than the number of categories, to avoid the \"dummy variable trap\"\n",
    "# See https://www.quora.com/When-do-I-fall-in-the-dummy-variable-trap\n",
    "features.drop(['age_25 - 45', 'sex_Female', 'degree_M'], axis=1, inplace=True)\n",
    "\n",
    "# Try to predict whether someone is re-arrested\n",
    "target = cv.two_year_recid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a logistic regression, so the coefficients are odds ratios (after undoing the logarithm.) Let's look at them to see what weights it used to make its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine regression coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model thinks that (for the non-violent data set):\n",
    "\n",
    "- being young (<25) more than doubles your odds of recidivism\n",
    "- but being >45 years old makes half as likely\n",
    "- being male increases your odds by 40%\n",
    "- every prior arrest increases your odds by 18%\n",
    "\n",
    "Now let's put our model through the same tests as we used on the COMPAS score to see how well this predictor does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab for our predictive model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print ppv, fpv, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can compare between White and Black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_metrics for white and black\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The limits of prediction\n",
    "Both COMPAS and our logistic regression classifier only get about 65% accuracy overall. Would it be possible to do better with are more sophisticated classifier or feature encoding? We can take a look at two variables at a time to try to see what's happening here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterpolot of age vs. priors, colored by two_year_recid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a  noise to the values in the array\n",
    "def jitter(arr):\n",
    "    # pick a standard deviation for the jitter of 3% of the data range\n",
    "    stdev = .02*(max(arr)-min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterpolot of age vs. sex, colored by two_year_recid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no way to draw a line (even a curved line) that cleanly separates the red (recidivated) and blue (did not recidivate) dots. We can do a little better by looking at more than two axes at a time, and might be able to imagine fitting a curved plane, but it's still not possible to separate red and blue enough to give us a very accurate classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
