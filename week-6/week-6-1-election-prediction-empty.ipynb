{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6-1: Election Prediction through simulation\n",
    "\n",
    "This is the first of two classes on election prediction. We'll be using simulation throughout to build our model.\n",
    "\n",
    "All data is downloaded from [Huffington Post Pollster](http://elections.huffingtonpost.com/pollster#historical-charts)\n",
    "\n",
    "Further references for your enjoyment:\n",
    "\n",
    "- [The Real Story of 2016](https://fivethirtyeight.com/features/the-real-story-of-2016/) - Fivethirtyeight\n",
    "- Buzzfeed's post-election [forecast grades](https://www.buzzfeednews.com/article/jsvine/2016-election-forecast-grades)\n",
    "- [Putting the Polling Miss of the 2016 Election in Perspective](https://www.nytimes.com/interactive/2016/11/13/upshot/putting-the-polling-miss-of-2016-in-perspective.html) - The Upshot\n",
    "- [After 2016, Can We Ever Trust the Polls Again?](https://newrepublic.com/article/139158/2016-can-ever-trust-polls-again) - The New Republic \n",
    "\n",
    "And finally, the single biggest reason that the simple election prediction model in this file misses so badly (predicting Clinton's chances in the high 90s): it does not take into account the [correlations between polling errors](https://www.quantamagazine.org/why-nate-silver-sam-wang-and-everyone-else-were-wrong-part-2-20161111/) in different states. If we fix this one factor, even our simple model will give Trump substantially higher chances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Simulating one poll\n",
    "\n",
    "Here we'll produce simulated election outcomes from a single poll. We are uncritically taking the poll results as an unbiased inidicator of results. This assumes that the people who are polled (\"likely voters\") are a good representation of the people who actually vote. It is possible to adjust these sorts of factors later, but let's begin with the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set a random seed so this whole notebook becomes deterministic (for teaching purposes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load national polling data. It's a TSV file, so we have to tell read_csv it's separated by tabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep only polls of \"likely voters\" (as opposed to registered voters, or republicans/democracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a margin of error to do our simulation, so drop any rows that don't have it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lot of polls here! Let's pick just one, near the end of the polling period (just before the election) and look at the outcomes it implies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pick a poll which showed a close race, because it better demonstrates how the margin of error works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The poll results and the margin of error define a probability distribution of \"true\" survey results -- that is, the result that the pollster would get if they could ask every single \"likely voter\" in the country. This distribution is a \"normal\" distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We reduce the problem to the difference between the two poll results, because that's what actually matters\n",
    "mean = poll.Clinton - poll.Trump\n",
    "\n",
    "# Some subtlety in calculating the stddev from the margin of error (MOE)\n",
    "#  - MOE is reported as 95% width, so we'd normally divide by 1.96 for standard deviation\n",
    "#  - But we want the stddev for a difference between two poll questions which are not independent.\n",
    "#    One more vote for Clinton is (almost always) one less vote for Trump. We need to multiply by nearly 2.\n",
    "#  - These almost perfectly cancel out, and stddev of the difference is near exactly MOE\n",
    "# See http://abcnews.go.com/images/PollingUnit/MOEFranklin.pdf\n",
    "stddev = poll.margin_of_error\n",
    "\n",
    "# For more general discussion of the MOE see \n",
    "# http://www.pewresearch.org/fact-tank/2016/09/08/understanding-the-margin-of-error-in-election-polls/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take samples from a normal distribution with this mean and standard deviation, to simulate what the underlying \"true\" voting pattern would be. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret this number, recall that we're simulating the Clinton-Trump difference. So positive means it goes for Clinton, who our poll says is ahead 46-44. Given this, we would expect more of the simulation results to go for Clinton. Let's make 1000 and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, the center of this distribution is at 2, the lead given by the polls. But many values are negative as well, meaning that Clinton doesn't always win (again, assuming the actual voters splt 46-44, as this poll suggests.)\n",
    "\n",
    "Let's see how often Trump wins, according to this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So about 24% according to this model. This makes sense becuase the margin of error (2.8%) is pretty wide relative to the difference between the polls (2%) \n",
    "\n",
    "If we run the simulation again, we'll get slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more samples we take, the less variation we'll see in this number. To demonstrate this, let's plot a histogram of the results for various numbers of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.normal(mean, stddev, 100), bins=20, density=True)\n",
    "plt.title('100 samples')\n",
    "plt.show()\n",
    "plt.hist(np.random.normal(mean, stddev, 1000), bins=20, density=True)\n",
    "plt.title('1,000 samples')\n",
    "plt.show()\n",
    "plt.hist(np.random.normal(mean, stddev, 10000), bins=20, density=True)\n",
    "plt.title('10,000 samples')\n",
    "plt.show()\n",
    "plt.hist(np.random.normal(mean, stddev, 100000), bins=20, density=True)\n",
    "plt.title('100,000 samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a reliable win percentage by counting the wins in a large sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Electoral college\n",
    "This shows how to interpret the uncertainty in a single poll -- at least the uncertainty in the margin of error. There are two major directions to go from here:\n",
    "\n",
    "1) In a real election prediction model, we would combine all the polls according to a weighted average of poll reliability. What \"reliability\" really means is how well the poll matched (predicted) previous election results. We can figure out the optimal combination of poll weights using, for example, linear regression.\n",
    "\n",
    "2) The US uses an electoral college system, where each state contributes a fixed number of votes (out of a total of 538). We definitely need to simulate that to get anything like a reasonable election prediction.\n",
    "\n",
    "So for the next step, let's see how to combine polls in the electoral college.\n",
    "\n",
    "Our first task will be to pick out one poll in each state. We'll use the last dated \"Likely Voter\" poll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV of electoral college votes for each state. \n",
    "# Ref: https://www.archives.gov/federal-register/electoral-college/allocation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a little Pandas trick to make merging in the poll data easier: \n",
    "# set the index to the abbreviation\n",
    "\n",
    "# And add the columns we'll need: Trump, Clinton, margin_of_error, all initially blank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not all polls have reported margins of error, but we can figure it out if we know the number of people surveyed.\n",
    "# This function salculate the 95% margin of error, using the classic formula. \n",
    "# Ref: https://onlinecourses.science.psu.edu/stat100/node/56/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we'll load polls for each state and pick one poll\n",
    "for abbr in states.abbr: \n",
    "    polls = pd.read_csv('data/' + abbr + '.tsv', sep='\\t')\n",
    "    polls = polls[polls.sample_subpopulation == 'Likely Voters']\n",
    "    poll = polls.tail(1).squeeze() \n",
    "\n",
    "    states.loc[abbr,'Trump'] = poll.Trump\n",
    "    states.loc[abbr,'Clinton'] = poll.Clinton\n",
    "\n",
    "    # There may be no MOE reported for this poll. If not, calculate it\n",
    "    moe = poll.margin_of_error\n",
    "    if pd.isnull(moe):\n",
    "        proportion = poll.Trump / 100  # or Clinton, will give nearly same result \n",
    "        moe = calc_moe(poll.observations, proportion)\n",
    "\n",
    "    states.loc[abbr,'margin_of_error'] = moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simulate an election by drawing a sample from each state election indpendently, then tallying the electoral college votes. Instead of looking at the distribution of Clinton-Trump vote, we'll just look at the distribution of EC votes for Clinton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_election(n_times):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 10 simulated elections and look at the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run many, many simulated elections and plot histogram of results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a Clinton win probability out of this, we can calculate the percentage where she receives 270 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Correlated errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with some random numbers\n",
    "mean=0\n",
    "stddev=1\n",
    "n=10\n",
    "np.random.normal(mean, stddev, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of these random numbers\n",
    "np.random.normal(mean, stddev, n).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_distribution_of_sums(make_a_sum_function, n_times):\n",
    "    sums = pd.DataFrame(np.zeros(n_times))\n",
    "    sums = sums.applymap(make_a_sum_function)\n",
    "    sums.plot(kind='hist', bins=20)\n",
    "    print(\"standard deviation\")\n",
    "    print(float(sums.std()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If take the sum of these random numbers 1000 times, what do we get?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But suppose that half of these random numbers were actually the *same* random number..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 4: Elections with correlated errors\n",
    "\n",
    "A poll is meant to tell us how people will vote in an election. But there will be some difference between the last latest polls before an election and the actual election results. According to [this research](http://www.stat.columbia.edu/~gelman/research/unpublished/polling-errors.pdf), US state level presidentail polls in the last three weeks before an election are off by an average of 2%.\n",
    "\n",
    "So we could simply add 2% to our margins of error. But this isn't quite right: when a poll is off in one state, it's often off in other states for similar reasons. The polling error is *correlated.* Not taking into account correlated polling errors were the [biggest reason](https://fivethirtyeight.com/features/election-update-why-our-model-is-more-bullish-than-others-on-trump/) that many 2016 election predictions were so badly off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what simply doubling the margin of error on every state does. This increases error, but not *correlated* error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to interpret results\n",
    "def plot_results(results):\n",
    "    plt.hist(results, bins=range(150, 500, 10), density=True)\n",
    "    plt.axvline(270, color='black', linestyle='dashed');\n",
    "    print(\"Clinton win probability: \" + str((results>=270).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need to add polling error that is similar between states. The simplest way to do this is just to add the same polling error to every state (perfectly correlated across all states!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_election_national_error(n_times, polling_error_stddev):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the distribution of electoral college outcomes look like with 2% correlated national polling error?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
